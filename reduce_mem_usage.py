# -*- coding: utf-8 -*-
"""reduce_mem_usage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sAB4Ot4xkVfjsMPZO6n3TGoqv70rPw-a
"""

def reduce_mem_usage(df, verbose=True):
    """
    The dataset is large and cannot be loaded with a simple read_csv call.
    This function is used to reduce memory of a pandas dataframe
    The idea is cast the numeric type to another more memory-effective type eg. from float64 to float32
    
    Iterate over every column
    Determine if the column is numeric
    Determine if the column can be represented by an integer
    Find the min and the max value
    Determine and apply the smallest datatype that can fit the range of values
    
    Source: 
    https://www.kaggle.com/gemartin/load-data-reduce-memory-usage

    Discussion:
    https://www.kaggle.com/c/champs-scalar-coupling/discussion/96655
    https://www.kaggle.com/mhviraf/why-i-wouldn-t-use-reduce-mem-usage
    
    """    
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    
    # df.memory_usage() will return how many bytes each column occupies
    # .sum() gives overall memory consumption:
    # result in kibibytes (KiB) converted to bytes by / 1024**2
    
    start_mem = df.memory_usage().sum() / 1024**2
    
    for col in df.columns:
        col_type = df[col].dtypes # determine datatype
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
                    
    end_mem = df.memory_usage().sum() / 1024**2
    
    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))
    return df